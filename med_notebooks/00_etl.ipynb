{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8b8b2bc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "import pandas as pd\n",
    "import psycopg2\n",
    "from io import StringIO\n",
    "import glob\n",
    "import os\n",
    "from dotenv import load_dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6c033005",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# For display\n",
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d30cb864",
   "metadata": {},
   "source": [
    "## A. Upload CSVs to S3 (using boto3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1754060b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîç Found CSV files: ['C:\\\\Users\\\\GIDI\\\\Desktop\\\\Folders\\\\REPOSITORY\\\\medoptix-ai-internship\\\\Datasets\\\\clinics.csv', 'C:\\\\Users\\\\GIDI\\\\Desktop\\\\Folders\\\\REPOSITORY\\\\medoptix-ai-internship\\\\Datasets\\\\dropout_flags.csv', 'C:\\\\Users\\\\GIDI\\\\Desktop\\\\Folders\\\\REPOSITORY\\\\medoptix-ai-internship\\\\Datasets\\\\feedback.csv', 'C:\\\\Users\\\\GIDI\\\\Desktop\\\\Folders\\\\REPOSITORY\\\\medoptix-ai-internship\\\\Datasets\\\\interventions.csv', 'C:\\\\Users\\\\GIDI\\\\Desktop\\\\Folders\\\\REPOSITORY\\\\medoptix-ai-internship\\\\Datasets\\\\patients.csv', 'C:\\\\Users\\\\GIDI\\\\Desktop\\\\Folders\\\\REPOSITORY\\\\medoptix-ai-internship\\\\Datasets\\\\sessions.csv']\n",
      "‚úÖ Uploaded: clinics.csv to s3://medoptix/datasets/clinics.csv\n",
      "‚úÖ Uploaded: dropout_flags.csv to s3://medoptix/datasets/dropout_flags.csv\n"
     ]
    }
   ],
   "source": [
    "# AWS S3 Configuration\n",
    "s3_client = boto3.client('s3')\n",
    "bucket_name = 'medoptix'\n",
    "prefix = 'datasets/'\n",
    "\n",
    "# ‚úÖ Correct path to your Datasets folder (adjust if needed)\n",
    "local_folder = r'C:\\Users\\GIDI\\Desktop\\Folders\\REPOSITORY\\medoptix-ai-internship\\Datasets'\n",
    "csv_files = glob.glob(os.path.join(local_folder, '*.csv'))\n",
    "\n",
    "print(\"üîç Found CSV files:\", csv_files)\n",
    "\n",
    "for file_path in csv_files:\n",
    "    try:\n",
    "        file_name = os.path.basename(file_path)\n",
    "        s3_key = f\"{prefix}{file_name}\"\n",
    "        \n",
    "        s3_client.upload_file(file_path, bucket_name, s3_key)\n",
    "        print(f\"‚úÖ Uploaded: {file_name} to s3://{bucket_name}/{s3_key}\")\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Failed to upload {file_name}: {e}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9579e8d4",
   "metadata": {},
   "source": [
    "## B. Load from S3 ‚Üí PostgreSQL\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d207fdbf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚¨áÔ∏è Downloaded patients.csv from S3\n",
      "‚¨áÔ∏è Downloaded clinics.csv from S3\n",
      "‚¨áÔ∏è Downloaded sessions.csv from S3\n",
      "‚¨áÔ∏è Downloaded feedback.csv from S3\n",
      "‚¨áÔ∏è Downloaded dropout_flags.csv from S3\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sqlalchemy import create_engine\n",
    "import boto3\n",
    "\n",
    "s3 = boto3.client(\"s3\")\n",
    "\n",
    "\n",
    "bucket = \"medoptix\"\n",
    "prefix = \"datasets/\"\n",
    "\n",
    "# Files to download\n",
    "files = [\"patients.csv\", \"clinics.csv\", \"sessions.csv\", \"feedback.csv\", \"dropout_flags.csv\"]\n",
    "\n",
    "# Download files\n",
    "for file in files:\n",
    "    s3.download_file(bucket, prefix + file, file)\n",
    "    print(f\"‚¨áÔ∏è Downloaded {file} from S3\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68acda84",
   "metadata": {},
   "source": [
    "# Data Modelling & Defining Foreign Key relationships\n",
    "\n",
    "\n",
    "- patients (PK: patient_id)\n",
    "- sessions (PK: session_id, FK: patient_id)\n",
    "- feedback (PK: feedback_id, FK: session_id)\n",
    "\n",
    "\n",
    "TASK 1 - Model and Define the relationship for the remaining set of dataset\n",
    " - clinics\n",
    " - dropout_flags\n",
    " - intervention.csv\n",
    "\n",
    "TASK 2 - Create Schema for these dataset and upload then into postgres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd463347",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7fbcd7e9",
   "metadata": {},
   "source": [
    "## C. Upload Data ‚Üí PostgreSQL\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4d560083",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PostgreSQL Configuration\n",
    "db_params = {\n",
    "    \"host\": os.getenv(\"DB_HOST\"),\n",
    "    \"port\": os.getenv(\"DB_PORT\"),\n",
    "    \"dbname\": os.getenv(\"DB_NAME\"),\n",
    "    \"user\": os.getenv(\"DB_USER\"),\n",
    "    \"password\": os.getenv(\"DB_PASSWORD\"),\n",
    "    \"sslmode\": os.getenv(\"DB_SSLMODE\")\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "507de508",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:1: SyntaxWarning: invalid escape sequence '\\p'\n",
      "<>:1: SyntaxWarning: invalid escape sequence '\\p'\n",
      "C:\\Users\\GIDI\\AppData\\Local\\Temp\\ipykernel_36256\\1397288755.py:1: SyntaxWarning: invalid escape sequence '\\p'\n",
      "  '''import pandas as pd\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'import pandas as pd\\nfrom sqlalchemy import create_engine\\nimport os\\nfrom dotenv import load_dotenv\\n\\n# Load environment variables (recommended for security)\\nload_dotenv()\\n\\ndef get_db_engine():\\n    \"\"\"Create and return a SQLAlchemy engine with proper connection string\"\"\"\\n    # Construct connection string from environment variables\\n    db_url = (\\n        f\"postgresql://{\\'\\'}:{\\'\\'}@\"\\n        f\"{\\'\\'}:{\\'\\'}/{\\'\\'}?\"\\n    )\\n    return create_engine(db_url)\\n\\ndef upload_data():\\n    # Step 1: Read CSV files\\n    patients = pd.read_csv(\"medoptix_data\\\\processed\\\\patients.csv\")\\n    sessions = pd.read_csv(\"medoptix_data\\\\processed\\\\sessions.csv\")\\n    feedback = pd.read_csv(\"C:/Users/Muham/Downloads/Medoptix_Demo/medoptix_data/processed/feedback.csv\")\\n\\n    # Step 2: Create database engine\\n    engine = get_db_engine()\\n\\n    # Step 3: Upload in referential order with error handling\\n    with engine.begin() as connection:  # Automatically handles transactions\\n        # Chunk size for large datasets (adjust as needed)\\n        chunk_size = 1000\\n\\n        # Upload patients table\\n        patients.to_sql(\\n            \"patients\", \\n            connection, \\n            if_exists=\"append\", \\n            index=False,\\n            chunksize=chunk_size,\\n            method=\\'multi\\'  # Faster for bulk inserts\\n        )\\n\\n        # Upload sessions table\\n        sessions.to_sql(\\n            \"sessions\", \\n            connection, \\n            if_exists=\"append\", \\n            index=False,\\n            chunksize=chunk_size,\\n            method=\\'multi\\'\\n        )\\n\\n        # Upload feedback table\\n        feedback.to_sql(\\n            \"feedback\", \\n            connection, \\n            if_exists=\"append\", \\n            index=False,\\n            chunksize=chunk_size,\\n            method=\\'multi\\'\\n        )\\n\\n    print(\"‚úÖ Data uploaded successfully with relationships intact.\")\\n\\nif __name__ == \"__main__\":\\n    upload_data() '"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''import pandas as pd\n",
    "from sqlalchemy import create_engine\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Load environment variables (recommended for security)\n",
    "load_dotenv()\n",
    "\n",
    "def get_db_engine():\n",
    "    \"\"\"Create and return a SQLAlchemy engine with proper connection string\"\"\"\n",
    "    # Construct connection string from environment variables\n",
    "    db_url = (\n",
    "        f\"postgresql://{''}:{''}@\"\n",
    "        f\"{''}:{''}/{''}?\"\n",
    "    )\n",
    "    return create_engine(db_url)\n",
    "\n",
    "def upload_data():\n",
    "    # Step 1: Read CSV files\n",
    "    patients = pd.read_csv(\"medoptix_data\\processed\\patients.csv\")\n",
    "    sessions = pd.read_csv(\"medoptix_data\\processed\\sessions.csv\")\n",
    "    feedback = pd.read_csv(\"C:/Users/Muham/Downloads/Medoptix_Demo/medoptix_data/processed/feedback.csv\")\n",
    "\n",
    "    # Step 2: Create database engine\n",
    "    engine = get_db_engine()\n",
    "\n",
    "    # Step 3: Upload in referential order with error handling\n",
    "    with engine.begin() as connection:  # Automatically handles transactions\n",
    "        # Chunk size for large datasets (adjust as needed)\n",
    "        chunk_size = 1000\n",
    "\n",
    "        # Upload patients table\n",
    "        patients.to_sql(\n",
    "            \"patients\", \n",
    "            connection, \n",
    "            if_exists=\"append\", \n",
    "            index=False,\n",
    "            chunksize=chunk_size,\n",
    "            method='multi'  # Faster for bulk inserts\n",
    "        )\n",
    "\n",
    "        # Upload sessions table\n",
    "        sessions.to_sql(\n",
    "            \"sessions\", \n",
    "            connection, \n",
    "            if_exists=\"append\", \n",
    "            index=False,\n",
    "            chunksize=chunk_size,\n",
    "            method='multi'\n",
    "        )\n",
    "\n",
    "        # Upload feedback table\n",
    "        feedback.to_sql(\n",
    "            \"feedback\", \n",
    "            connection, \n",
    "            if_exists=\"append\", \n",
    "            index=False,\n",
    "            chunksize=chunk_size,\n",
    "            method='multi'\n",
    "        )\n",
    "\n",
    "    print(\"‚úÖ Data uploaded successfully with relationships intact.\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    upload_data() '''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef694993",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2c469388",
   "metadata": {},
   "source": [
    "## D. Read Data ‚Üí PostgreSQL - (Prepare data for EDA)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2643d569",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sqlalchemy import create_engine\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "def get_db_engine():\n",
    "    \"\"\"Create and return a SQLAlchemy engine with proper connection string\"\"\"\n",
    "    # Construct connection string from environment variables\n",
    "    db_url = (\n",
    "        f\"postgresql://{''}:{''}@\"\n",
    "        f\"{''}:{''}/{''}?\"\n",
    "    )\n",
    "    return create_engine(db_url)\n",
    "\n",
    "\n",
    "engine = get_db_engine()\n",
    "\n",
    "\n",
    "# Query to fetch data from the tables\n",
    "patients_query = \"SELECT * FROM patients\"\n",
    "sessions_query = \"SELECT * FROM sessions\"\n",
    "feedback_query = \"SELECT * FROM feedback\"\n",
    "\n",
    "# Load data into pandas DataFrame\n",
    "patients_df = pd.read_sql(patients_query, engine)\n",
    "sessions_df = pd.read_sql(sessions_query, engine)\n",
    "feedback_df = pd.read_sql(feedback_query, engine)\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mlenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
