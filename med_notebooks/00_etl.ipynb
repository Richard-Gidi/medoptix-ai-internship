{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8b8b2bc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "import pandas as pd\n",
    "import psycopg2\n",
    "from io import StringIO\n",
    "import glob\n",
    "import os\n",
    "from dotenv import load_dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6c033005",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# For display\n",
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d30cb864",
   "metadata": {},
   "source": [
    "## Upload CSVs to S3 (using boto3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1754060b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîç Found CSV files: ['C:\\\\Users\\\\GIDI\\\\Desktop\\\\Folders\\\\REPOSITORY\\\\medoptix-ai-internship\\\\Datasets\\\\clinics.csv', 'C:\\\\Users\\\\GIDI\\\\Desktop\\\\Folders\\\\REPOSITORY\\\\medoptix-ai-internship\\\\Datasets\\\\dropout_flags.csv', 'C:\\\\Users\\\\GIDI\\\\Desktop\\\\Folders\\\\REPOSITORY\\\\medoptix-ai-internship\\\\Datasets\\\\feedback.csv', 'C:\\\\Users\\\\GIDI\\\\Desktop\\\\Folders\\\\REPOSITORY\\\\medoptix-ai-internship\\\\Datasets\\\\interventions.csv', 'C:\\\\Users\\\\GIDI\\\\Desktop\\\\Folders\\\\REPOSITORY\\\\medoptix-ai-internship\\\\Datasets\\\\patients.csv', 'C:\\\\Users\\\\GIDI\\\\Desktop\\\\Folders\\\\REPOSITORY\\\\medoptix-ai-internship\\\\Datasets\\\\sessions.csv']\n",
      "‚úÖ Uploaded: clinics.csv to s3://medoptix/datasets/clinics.csv\n",
      "‚úÖ Uploaded: dropout_flags.csv to s3://medoptix/datasets/dropout_flags.csv\n"
     ]
    }
   ],
   "source": [
    "''' # AWS S3 Configuration\n",
    "s3_client = boto3.client('s3')\n",
    "bucket_name = 'medoptix'\n",
    "prefix = 'datasets/'\n",
    "\n",
    "# Correct path to your Datasets folder (adjust if needed)\n",
    "local_folder = r'C:\\Users\\GIDI\\Desktop\\Folders\\REPOSITORY\\medoptix-ai-internship\\Datasets'\n",
    "csv_files = glob.glob(os.path.join(local_folder, '*.csv'))\n",
    "\n",
    "print(\"üîç Found CSV files:\", csv_files)\n",
    "\n",
    "for file_path in csv_files:\n",
    "    try:\n",
    "        file_name = os.path.basename(file_path)\n",
    "        s3_key = f\"{prefix}{file_name}\"\n",
    "        \n",
    "        s3_client.upload_file(file_path, bucket_name, s3_key)\n",
    "        print(f\" Uploaded: {file_name} to s3://{bucket_name}/{s3_key}\")\n",
    "    except Exception as e:\n",
    "        print(f\" Failed to upload {file_name}: {e}\") '''\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9579e8d4",
   "metadata": {},
   "source": [
    "## Load from S3 ‚Üí PostgreSQL\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d207fdbf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'for file in files:\\n    s3.download_file(bucket, prefix + file, file)\\n    print(f\"‚¨áÔ∏è Downloaded {file} from S3\")'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sqlalchemy import create_engine\n",
    "import boto3\n",
    "\n",
    "s3 = boto3.client(\"s3\")\n",
    "\n",
    "\n",
    "bucket = \"medoptix\"\n",
    "prefix = \"datasets/\"\n",
    "\n",
    "# Files to download\n",
    "files = [\"patients.csv\", \"clinics.csv\", \"sessions.csv\", \"feedback.csv\", \"dropout_flags.csv\"]\n",
    "\n",
    "# Download files\n",
    "'''for file in files:\n",
    "    s3.download_file(bucket, prefix + file, file)\n",
    "    print(f\"‚¨áÔ∏è Downloaded {file} from S3\")'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68acda84",
   "metadata": {},
   "source": [
    "# Data Modelling & Defining Foreign Key relationships\n",
    "\n",
    "\n",
    "- patients (PK: patient_id)\n",
    "- sessions (PK: session_id, FK: patient_id)\n",
    "- feedback (PK: feedback_id, FK: session_id)\n",
    "\n",
    "\n",
    "TASK 1 - Model and Define the relationship for the remaining set of dataset\n",
    " - clinics\n",
    " - dropout_flags\n",
    " - intervention.csv\n",
    "\n",
    "TASK 2 - Create Schema for these dataset and upload then into postgres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd463347",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7fbcd7e9",
   "metadata": {},
   "source": [
    "##  Upload Data ‚Üí PostgreSQL\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4d560083",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PostgreSQL Configuration\n",
    "db_params = {\n",
    "    \"host\": os.getenv(\"DB_HOST\"),\n",
    "    \"port\": os.getenv(\"DB_PORT\"),\n",
    "    \"dbname\": os.getenv(\"DB_NAME\"),\n",
    "    \"user\": os.getenv(\"DB_USER\"),\n",
    "    \"password\": os.getenv(\"DB_PASSWORD\"),\n",
    "    \"sslmode\": os.getenv(\"DB_SSLMODE\")\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "507de508",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All datasets loaded from S3 and inserted into PostgreSQL successfully.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sqlalchemy import create_engine, text\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Load env credentials for PostgreSQL\n",
    "load_dotenv()\n",
    "\n",
    "db_url = (\n",
    "    f\"postgresql://{os.getenv('DB_USER')}:{os.getenv('DB_PASSWORD')}@\"\n",
    "    f\"{os.getenv('DB_HOST')}:{os.getenv('DB_PORT')}/{os.getenv('DB_NAME')}\"\n",
    ")\n",
    "engine = create_engine(db_url)\n",
    "\n",
    "# --- S3 CONFIG (pandas + s3fs handles this internally) ---\n",
    "bucket = \"medoptix\"\n",
    "prefix = \"datasets/\"\n",
    "files = {\n",
    "    \"patients\": f\"s3://{bucket}/{prefix}patients.csv\",\n",
    "    \"clinics\": f\"s3://{bucket}/{prefix}clinics.csv\",\n",
    "    \"sessions\": f\"s3://{bucket}/{prefix}sessions.csv\",\n",
    "    \"feedback\": f\"s3://{bucket}/{prefix}feedback.csv\",\n",
    "    \"interventions\": f\"s3://{bucket}/{prefix}interventions.csv\",\n",
    "    \"dropout\": f\"s3://{bucket}/{prefix}dropout_flags.csv\",\n",
    "}\n",
    "\n",
    "# READ DATA FROM S3 DIRECTLY INTO DATAFRAMES\n",
    "patients = pd.read_csv(files[\"patients\"], storage_options={\"anon\": False})\n",
    "clinics = pd.read_csv(files[\"clinics\"], storage_options={\"anon\": False})\n",
    "sessions = pd.read_csv(files[\"sessions\"], storage_options={\"anon\": False}, parse_dates=['date'])\n",
    "feedback = pd.read_csv(files[\"feedback\"], storage_options={\"anon\": False})\n",
    "interventions = pd.read_csv(files[\"interventions\"], storage_options={\"anon\": False}, parse_dates=['sent_at'])\n",
    "dropout = pd.read_csv(files[\"dropout\"], storage_options={\"anon\": False})\n",
    "\n",
    "# CREATE TABLES IN POSTGRESQL \n",
    "with engine.begin() as conn:\n",
    "    conn.execute(text(\"\"\"\n",
    "        CREATE TABLE IF NOT EXISTS dim_clinics (\n",
    "            clinic_id INT PRIMARY KEY,\n",
    "            city TEXT,\n",
    "            country TEXT,\n",
    "            type TEXT,\n",
    "            postcode TEXT,\n",
    "            capacity INT,\n",
    "            staff_count INT,\n",
    "            speciality TEXT,\n",
    "            avg_rating FLOAT\n",
    "        );\n",
    "\n",
    "        CREATE TABLE IF NOT EXISTS dim_patients (\n",
    "            patient_id INT PRIMARY KEY,\n",
    "            age INT,\n",
    "            gender TEXT,\n",
    "            bmi FLOAT,\n",
    "            smoker BOOLEAN,\n",
    "            chronic_cond TEXT,\n",
    "            injury_type TEXT,\n",
    "            signup_date TIMESTAMP,\n",
    "            referral_source TEXT,\n",
    "            consent BOOLEAN,\n",
    "            clinic_id INT REFERENCES dim_clinics(clinic_id),\n",
    "            insurance_type TEXT\n",
    "        );\n",
    "\n",
    "        CREATE TABLE IF NOT EXISTS fact_sessions (\n",
    "            session_id UUID PRIMARY KEY,\n",
    "            patient_id INT REFERENCES dim_patients(patient_id),\n",
    "            date TIMESTAMP,\n",
    "            week INT,\n",
    "            duration INT,\n",
    "            pain_level INT,\n",
    "            exercise_type TEXT,\n",
    "            home_adherence_pc FLOAT,\n",
    "            satisfaction INT,\n",
    "            therapist_id INT\n",
    "        );\n",
    "\n",
    "        CREATE TABLE IF NOT EXISTS fact_feedback (\n",
    "            feedback_id UUID PRIMARY KEY,\n",
    "            session_id UUID REFERENCES fact_sessions(session_id),\n",
    "            comments TEXT,\n",
    "            sentiment FLOAT\n",
    "        );\n",
    "\n",
    "        CREATE TABLE IF NOT EXISTS fact_interventions (\n",
    "            intervention_id UUID PRIMARY KEY,\n",
    "            patient_id INT REFERENCES dim_patients(patient_id),\n",
    "            sent_at TIMESTAMP,\n",
    "            channel TEXT,\n",
    "            message TEXT,\n",
    "            responded TEXT\n",
    "        );\n",
    "\n",
    "        CREATE TABLE IF NOT EXISTS fact_dropout_flags (\n",
    "            patient_id INT PRIMARY KEY REFERENCES dim_patients(patient_id),\n",
    "            dropout BOOLEAN,\n",
    "            dropout_week INT\n",
    "        );\n",
    "    \"\"\"))\n",
    "\n",
    "# --- UPLOAD DATA TO POSTGRES ---\n",
    "clinics.to_sql('dim_clinics', engine, if_exists='append', index=False)\n",
    "patients.to_sql('dim_patients', engine, if_exists='append', index=False)\n",
    "sessions.to_sql('fact_sessions', engine, if_exists='append', index=False)\n",
    "feedback.to_sql('fact_feedback', engine, if_exists='append', index=False)\n",
    "interventions.to_sql('fact_interventions', engine, if_exists='append', index=False)\n",
    "dropout.to_sql('fact_dropout_flags', engine, if_exists='append', index=False)\n",
    "\n",
    "print(\"All datasets loaded from S3 and inserted into PostgreSQL successfully.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mlenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
